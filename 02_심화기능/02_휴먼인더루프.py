'''
íœ´ë¨¼ ì¸ ë” ë£¨í”„ ë°©ì‹ì€ ì¤‘ìš” ì˜ì‚¬ ê²°ì • ì‚¬í•­ì—ì„œ ì¸ê°„ì˜ íŒë‹¨ì´ ê°œì…ë˜ëŠ” êµ¬ì¡°
ì²´í¬í¬ì¸íŠ¸ì˜ í•µì‹¬ í™œìš© ì‚¬ë¡€
[ì‹¤í–‰íë¦„]
1. draft â†’ AI ì´ˆì•ˆ ì‘ì„±
2. wait_approval ì „ì— INTERRUPT â¸ï¸
3. [ì‚¬ëŒ ê°œì…] ìŠ¹ì¸ or ìˆ˜ì • ìš”ì²­
4. update_stateë¡œ ê²°ì • ë°˜ì˜
5. invoke(None) â†’ ì¬ê°œ
6. final â†’ ìµœì¢… ì‘ë‹µ
7. END
'''

from langchain_ollama import ChatOllama
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict, Annotated, Literal
from langchain_core.messages import HumanMessage, AIMessage
import operator

# ìƒíƒœ ì •ì˜
class ApprovalState(TypedDict):
    messages: Annotated[list, operator.add]
    draft_response: str  # AIê°€ ì‘ì„±í•œ ì´ˆì•ˆ
    approved: bool  # ìŠ¹ì¸ ì—¬ë¶€
    user_feedback: str  # ì‚¬ìš©ì í”¼ë“œë°±

# LLM
llm = ChatOllama(
    model="qwen2.5:3b",
    base_url="http://localhost:11434",
    temperature=0.7
)

# ì´ˆì•ˆ ì‘ì„± ë…¸ë“œ
def draft_response_node(state: ApprovalState) -> ApprovalState:
    """AIê°€ ë‹µë³€ ì´ˆì•ˆì„ ì‘ì„±"""
    messages = state["messages"]
    
    system_prompt = """ë‹¹ì‹ ì€ ê³ ê° ì‘ëŒ€ AIì…ë‹ˆë‹¤.
                        ê³ ê° ë¬¸ì˜ì— ëŒ€í•œ ë‹µë³€ ì´ˆì•ˆì„ ì‘ì„±í•˜ì„¸ìš”.
                        ì´ ë‹µë³€ì€ ì‚¬ëŒì˜ ê²€í† ë¥¼ ê±°ì¹  ì˜ˆì •ì…ë‹ˆë‹¤."""
    
    full_messages = [HumanMessage(content=system_prompt)] + messages
    response = llm.invoke(full_messages)
    
    print(f"\nğŸ“ AI ì´ˆì•ˆ ì‘ì„± ì™„ë£Œ:")
    print(f"{response.content}\n")
    
    return {
        "draft_response": response.content,
        "approved": False
    }

# ìŠ¹ì¸ ëŒ€ê¸° ë…¸ë“œ
def wait_for_approval_node(state: ApprovalState) -> ApprovalState:
    """ì‚¬ëŒì˜ ìŠ¹ì¸ì„ ëŒ€ê¸° (ì‹¤ì œë¡œëŠ” interrupt ë°œìƒ)"""
    print("â¸ì‚¬ëŒì˜ ìŠ¹ì¸ ëŒ€ê¸° ì¤‘...")
    return state

# ìµœì¢… ì‘ë‹µ ë…¸ë“œ
def final_response_node(state: ApprovalState) -> ApprovalState:
    """ìŠ¹ì¸ëœ ë‹µë³€ ë˜ëŠ” ìˆ˜ì •ëœ ë‹µë³€ ë°˜ì˜"""
    
    if state.get("user_feedback"):
        # í”¼ë“œë°±ì´ ìˆìœ¼ë©´ ìˆ˜ì •
        print(f"\nğŸ”„ ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜: {state['user_feedback']}")
        
        revision_prompt = f"""ì›ë˜ ë‹µë³€: {state['draft_response']}

                                ì‚¬ìš©ì í”¼ë“œë°±: {state['user_feedback']}

                                ìœ„ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ë‹µë³€ì„ ìˆ˜ì •í•˜ì„¸ìš”."""
        
        response = llm.invoke([HumanMessage(content=revision_prompt)])
        final = response.content
    else:
        # í”¼ë“œë°± ì—†ìœ¼ë©´ ì´ˆì•ˆ ê·¸ëŒ€ë¡œ
        final = state["draft_response"]
    
    print(f"\nâœ… ìµœì¢… ë‹µë³€:")
    print(f"{final}\n")
    
    return {
        "messages": [AIMessage(content=final)],
        "approved": True
    }

# ë¼ìš°íŒ… í•¨ìˆ˜
def check_approval(state: ApprovalState) -> Literal["approved", "wait"]:
    """ìŠ¹ì¸ ì—¬ë¶€ í™•ì¸"""
    if state.get("approved", False):
        return "approved"
    return "wait"

# ê·¸ë˜í”„ ìƒì„±
workflow = StateGraph(ApprovalState)

workflow.add_node("draft", draft_response_node)
workflow.add_node("wait_approval", wait_for_approval_node)
workflow.add_node("final", final_response_node)

workflow.set_entry_point("draft")

# draft â†’ wait_approval
workflow.add_edge("draft", "wait_approval")

# wait_approval â†’ interrupt (ì‚¬ëŒ ê°œì…)
# ì´ ë¶€ë¶„ì€ ì•„ë˜ì—ì„œ ì„¤ëª…

workflow.add_conditional_edges(
    "wait_approval",
    check_approval,
    {
        "approved": "final",
        "wait": END  # ì„ì‹œë¡œ END (ì‹¤ì œë¡œëŠ” interrupt)
    }
)

workflow.add_edge("final", END)

# ë©”ëª¨ë¦¬ ì²´í¬í¬ì¸í„°
memory = MemorySaver()

app = workflow.compile(
    checkpointer=memory,
    interrupt_before=["wait_approval"]  # ì´ ë…¸ë“œ ì „ì— ì¤‘ë‹¨
)

# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("=== íœ´ë¨¼-ì¸-ë”-ë£¨í”„ í…ŒìŠ¤íŠ¸ ===\n")
    
    # 1ë‹¨ê³„: ì´ˆì•ˆ ì‘ì„±
    config = {"configurable": {"thread_id": "approval_test_1"}}
    
    initial_state = {
        "messages": [HumanMessage(content="í™˜ë¶ˆ ì •ì±…ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?")],
        "draft_response": "",
        "approved": False,
        "user_feedback": ""
    }
    
    print("[1ë‹¨ê³„] AI ì´ˆì•ˆ ì‘ì„± ì‹œì‘...")
    result = app.invoke(initial_state, config=config)
    
    # í˜„ì¬ ìƒíƒœ í™•ì¸
    current_state = app.get_state(config)
    print(f"í˜„ì¬ ë…¸ë“œ: {current_state.next}")
    print(f"ì´ˆì•ˆ: {current_state.values['draft_response'][:100]}...\n")
    
    # 2ë‹¨ê³„: ì‚¬ìš©ì ìŠ¹ì¸ ì‹œë®¬ë ˆì´ì…˜
    print("\n" + "="*60)
    print("[ì‚¬ìš©ì ì„ íƒ]")
    print("1. ìŠ¹ì¸")
    print("2. ìˆ˜ì • ìš”ì²­")
    choice = input("ì„ íƒ (1 or 2): ")
    
    if choice == "1":
        # ìŠ¹ì¸
        print("\n[2ë‹¨ê³„] ìŠ¹ì¸ë¨")
        app.update_state(config, {"approved": True})
        
    else:
        # ìˆ˜ì • ìš”ì²­
        feedback = input("\nìˆ˜ì • ìš”ì²­ ë‚´ìš©: ")
        print(f"\n[2ë‹¨ê³„] ìˆ˜ì • ìš”ì²­: {feedback}")
        app.update_state(config, {
            "approved": True,
            "user_feedback": feedback
        })
    
    # 3ë‹¨ê³„: ìµœì¢… ì‘ë‹µ ìƒì„±
    print("\n[3ë‹¨ê³„] ìµœì¢… ì‘ë‹µ ìƒì„±...")
    final_result = app.invoke(None, config=config)
    
    print("\n=== ì™„ë£Œ ===")
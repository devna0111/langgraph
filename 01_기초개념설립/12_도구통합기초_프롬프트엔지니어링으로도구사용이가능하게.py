from langchain_core.tools import tool
from langchain_ollama import ChatOllama
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated, Literal
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
import operator
import re

# ë„êµ¬ ì •ì˜
@tool
def get_weather(city: str) -> str:
    """íŠ¹ì • ë„ì‹œì˜ ë‚ ì”¨ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    weather_data = {
        "ì„œìš¸": "ë§‘ìŒ, 15ë„",
        "ë¶€ì‚°": "íë¦¼, 18ë„",
        "ì œì£¼": "ë¹„, 20ë„"
    }
    return weather_data.get(city, f"{city}ì˜ ë‚ ì”¨ ì •ë³´ ì—†ìŒ")

@tool
def calculate(expression: str) -> str:
    """ìˆ˜ì‹ì„ ê³„ì‚°í•©ë‹ˆë‹¤. ì˜ˆ: 2+3, 15*23"""
    try:
        result = eval(expression, {"__builtins__": {}})
        return str(result)
    except Exception as e:
        return f"ê³„ì‚° ì˜¤ë¥˜: {str(e)}"

@tool
def get_current_time() -> str:
    """í˜„ì¬ ì‹œê°„ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# ë„êµ¬ ë”•ì…”ë„ˆë¦¬
tools_map = {
    "get_weather": get_weather,
    "calculate": calculate,
    "get_current_time": get_current_time
}

# ìƒíƒœ ì •ì˜
class AgentState(TypedDict):
    messages: Annotated[list, operator.add]
    tool_executed: bool

# LLM
llm = ChatOllama(
    model="devna0111-7b-q4",  # íŒŒì¸íŠœë‹ ëª¨ë¸ ì‚¬ìš©!
    base_url="http://localhost:11434",
    temperature=0
)

# ë„êµ¬ ì„¤ëª… ìƒì„±
def get_tools_description():
    descriptions = []
    for name, tool_func in tools_map.items():
        desc = tool_func.description
        descriptions.append(f"- {name}: {desc}")
    return "\n".join(descriptions)

# ì—ì´ì „íŠ¸ ë…¸ë“œ
def agent_node(state: AgentState) -> AgentState:
    messages = state["messages"]
    tool_executed = state.get("tool_executed", False)
    
    # ë„êµ¬ ì‹¤í–‰ í›„ë¼ë©´ ìµœì¢… ë‹µë³€ ëª¨ë“œ
    if tool_executed:
        system_prompt = """ì´ì „ì— ë„êµ¬ë¥¼ ì‹¤í–‰í•œ ê²°ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.
ì´ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
ë„êµ¬ í˜•ì‹(TOOL:/INPUT:)ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."""
    else:
        # ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥ ëª¨ë“œ
        system_prompt = f"""ë‹¹ì‹ ì€ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
{get_tools_description()}

**ì¤‘ìš”**: ë„êµ¬ê°€ í•„ìš”í•˜ë©´ **ë°˜ë“œì‹œ** ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
TOOL: ë„êµ¬ì´ë¦„
INPUT: ì…ë ¥ê°’

ì˜ˆì‹œ:
ì§ˆë¬¸: "ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜"
ë‹µë³€:
TOOL: get_weather
INPUT: ì„œìš¸

ì§ˆë¬¸: "15 ê³±í•˜ê¸° 23ì€?"
ë‹µë³€:
TOOL: calculate
INPUT: 15*23

ì§ˆë¬¸: "ì§€ê¸ˆ ëª‡ ì‹œì•¼?"
ë‹µë³€:
TOOL: get_current_time
INPUT: 

ë„êµ¬ê°€ í•„ìš”ì—†ëŠ” ì¼ë°˜ ëŒ€í™”ëŠ” ê·¸ëƒ¥ ë‹µë³€í•˜ì„¸ìš”."""

    full_messages = [SystemMessage(content=system_prompt)] + messages
    response = llm.invoke(full_messages)
    
    return {"messages": [response], "tool_executed": False}

# ë„êµ¬ ì‹¤í–‰ ë…¸ë“œ
def tool_execution_node(state: AgentState) -> AgentState:
    last_message = state["messages"][-1]
    content = last_message.content
    
    # TOOL: íŒ¨í„´ íŒŒì‹±
    tool_match = re.search(r'TOOL:\s*(\w+)', content, re.IGNORECASE)
    input_match = re.search(r'INPUT:\s*(.+?)(?:\n|$)', content, re.IGNORECASE | re.DOTALL)
    
    if tool_match:
        tool_name = tool_match.group(1).strip()
        tool_input = input_match.group(1).strip() if input_match else ""
        
        print(f"ğŸ”§ ë„êµ¬ ì‹¤í–‰: {tool_name}('{tool_input}')")
        
        if tool_name in tools_map:
            try:
                result = tools_map[tool_name].invoke(tool_input)
                print(f"âœ… ê²°ê³¼: {result}")
                
                # ë„êµ¬ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ë©”ì‹œì§€ë¡œ ì¶”ê°€
                result_msg = HumanMessage(
                    content=f"[ë„êµ¬ ì‹¤í–‰ ê²°ê³¼]\në„êµ¬: {tool_name}\nì…ë ¥: {tool_input}\nê²°ê³¼: {result}\n\nìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë‹µë³€í•˜ì„¸ìš”."
                )
                return {"messages": [result_msg], "tool_executed": True}
            except Exception as e:
                error_msg = HumanMessage(
                    content=f"ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}\nì‚¬ìš©ìì—ê²Œ ì˜¤ë¥˜ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."
                )
                return {"messages": [error_msg], "tool_executed": True}
        else:
            error_msg = HumanMessage(
                content=f"'{tool_name}' ë„êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ ì•Œë ¤ì£¼ì„¸ìš”."
            )
            return {"messages": [error_msg], "tool_executed": True}
    
    return {"tool_executed": False}

# ë¼ìš°íŒ… í•¨ìˆ˜
def should_use_tool(state: AgentState) -> Literal["tools", "end"]:
    last_message = state["messages"][-1]
    
    # ë„êµ¬ ì‹¤í–‰ í›„ë¼ë©´ ì¢…ë£Œ
    if state.get("tool_executed", False):
        return "end"
    
    # TOOL: íŒ¨í„´ì´ ìˆìœ¼ë©´ ë„êµ¬ ì‹¤í–‰
    if "TOOL:" in last_message.content or "tool:" in last_message.content:
        return "tools"
    
    return "end"

# ê·¸ë˜í”„ ìƒì„±
workflow = StateGraph(AgentState)

workflow.add_node("agent", agent_node)
workflow.add_node("tools", tool_execution_node)

workflow.set_entry_point("agent")

workflow.add_conditional_edges(
    "agent",
    should_use_tool,
    {
        "tools": "tools",
        "end": END
    }
)

# ë„êµ¬ ì‹¤í–‰ í›„ ë‹¤ì‹œ agentë¡œ (ìµœì¢… ë‹µë³€ ìƒì„±)
workflow.add_edge("tools", "agent")

app = workflow.compile()

# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("=== í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë°˜ ë„êµ¬ ì‚¬ìš© ===\n")
    
    test_cases = [
        "ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜",
        "15 ê³±í•˜ê¸° 23ì€?",
        "ì§€ê¸ˆ ëª‡ ì‹œì•¼?",
        "ì•ˆë…•í•˜ì„¸ìš”"  # ë„êµ¬ ì—†ì´ ì¼ë°˜ ëŒ€í™”
    ]
    
    for i, query in enumerate(test_cases, 1):
        print(f"[í…ŒìŠ¤íŠ¸ {i}] {query}")
        print("-" * 60)
        
        result = app.invoke({
            "messages": [HumanMessage(content=query)],
            "tool_executed": False
        })
        
        print(f"ìµœì¢… ë‹µë³€: {result['messages'][-1].content}\n")
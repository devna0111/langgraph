from langgraph.graph import StateGraph, END
from langchain_community.llms import Ollama
from typing import TypedDict, List
import re
def create_hybrid_multi_agent():
    """í•˜ì´ë¸Œë¦¬ë“œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ìƒì„±"""
    print("==== í•˜ì´ë¸Œë¦¬ë“œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ìƒì„± ì‹œì‘ ====")
    
    try:
        # 1. ê³µìœ  ìƒíƒœ ì •ì˜
        class MultiAgentState(TypedDict):
            user_request: str # ì‚¬ìš©ì ìš”ì²­
            research_data: str # ì—°êµ¬ìê°€ ìˆ˜ì§‘í•œ ë°ì´í„°
            analysis_result: str # ë¶„ì„ ê²°ê³¼ (í•¨ìˆ˜ ë…¸ë“œ)
            draft_content: str # ì‘ê°€ê°€ ì‘ì„±í•œ ì´ˆì•ˆ
            final_output: str # ìµœì¢… ê²°ê³¼
            current_step: str # í˜„ì¬ ì§„í–‰ ë‹¨ê³„
            metadata: dict # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
        
        # 2. LLM ì„¤ì •
        llm = Ollama(
            model="devna0111-7b-q4",
            base_url="http://localhost:11434",
            temperature=0.15,
        )
        
        # 3. ì—°êµ¬ì Agent (LLM + ì‹¤ì œ ê²€ìƒ‰ ë„êµ¬)
        def researcher_agent(state: MultiAgentState):
            """ì—°êµ¬ì Agent - ì‹¤ì œ duckduckgo-search í™œìš©"""
            print("==== ì—°êµ¬ì Agent ì‘ì—… ì‹œì‘")
            
            user_request = state['user_request']
            
            # ê²€ìƒ‰ì´ í•„ìš”í•œì§€ LLMì´ íŒë‹¨
            search_prompt = f"""
                                ì‚¬ìš©ì ìš”ì²­: {user_request}

                                ì´ ìš”ì²­ì— ëŒ€í•´ ì¸í„°ë„· ê²€ìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨í•˜ê³ , í•„ìš”í•˜ë‹¤ë©´ ì ì ˆí•œ ê²€ìƒ‰ì–´ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.

                                ì‘ë‹µ í˜•ì‹ :
                                - ê²€ìƒ‰ í•„ìš”: ì˜ˆ/ì•„ë‹ˆì˜¤
                                - ê²€ìƒ‰ì–´: (í•„ìš”í•œ ê²½ìš°ë§Œ)
                                - ì´ìœ : (ê°„ë‹¨í•œ ì„¤ëª…)
                                """
            
            search_decision = llm.invoke(search_prompt)
            print(f"==== ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨: {search_decision[:100]}...")
            
            # ì‹¤ì œ ê²€ìƒ‰ ì‹¤í–‰
            if "ê²€ìƒ‰ í•„ìš”: ì˜ˆ" in search_decision or "í•„ìš”: ì˜ˆ" in search_decision:
                try:
                    from ddgs import DDGS # duckduckgo_search
                    
                    # ê²€ìƒ‰ì–´ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­)
                    search_keywords = user_request.replace("ì— ëŒ€í•´", "").replace("ì•Œë ¤ì¤˜", "").replace("ë¶„ì„í•´ì¤˜", "").strip()
                    print(f"==== ê²€ìƒ‰ì–´: {search_keywords}")
                    
                    # ì‹¤ì œ DuckDuckGo ê²€ìƒ‰
                    with DDGS() as ddgs:
                        search_results = list(ddgs.text(search_keywords, max_results=5))
                    
                    if search_results:
                        # ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…
                        formatted_results = []
                        for i, result in enumerate(search_results, 1):
                            title = result.get('title', 'ì œëª© ì—†ìŒ')
                            body = result.get('body', 'ë‚´ìš© ì—†ìŒ')
                            url = result.get('href', '')
                            
                            formatted_results.append(f"""
                                                    {i}. {title}
                                                    ë‚´ìš©: {body[:200]}...
                                                    ì¶œì²˜: {url}
                                                    """)
                        
                        research_data = f"""
                                        ==== '{search_keywords}' ê²€ìƒ‰ ê²°ê³¼:

                                        {''.join(formatted_results)}

                                        ì´ {len(search_results)}ê°œì˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.
                                        """
                        print(f"==== ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
                    else:
                        research_data = f"'{search_keywords}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        print("==== ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                
                except ImportError:
                    print("**** duckduckgo-search ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
                    research_data = f"""
                                        *** duckduckgo-search ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
                                        ì„¤ì¹˜ ëª…ë ¹ì–´: pip install duckduckgo-search

                                        '{user_request}'ì— ëŒ€í•œ ê¸°ë³¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤:
                                        - í•´ë‹¹ ì£¼ì œëŠ” í˜„ì¬ ê´€ì‹¬ì´ ë†’ì€ ë¶„ì•¼ì…ë‹ˆë‹¤.
                                        - ë” ìì„¸í•œ ì •ë³´ë¥¼ ìœ„í•´ì„œëŠ” ì‹¤ì œ ê²€ìƒ‰ì´ í•„ìš”í•©ë‹ˆë‹¤.
                                        """
                
                except Exception as e:
                    print(f"**** ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                    research_data = f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            
            else:
                research_data = f"'{user_request}'ì— ëŒ€í•œ ê²€ìƒ‰ì´ ë¶ˆí•„ìš”í•˜ì—¬ ê¸°ë³¸ ì§€ì‹ì„ í™œìš©í•©ë‹ˆë‹¤."
                search_keywords = None
            
            return {
                "user_request": state['user_request'],
                "research_data": research_data,
                "analysis_result": state.get('analysis_result', ''),
                "draft_content": state.get('draft_content', ''),
                "final_output": state.get('final_output', ''),
                "current_step": "research_complete",
                "metadata": {
                    "search_performed": "ê²€ìƒ‰ í•„ìš”: ì˜ˆ" in search_decision,
                    "search_keywords": search_keywords,
                    "search_results_count": len(search_results) if "ê²€ìƒ‰ í•„ìš”: ì˜ˆ" in search_decision and 'search_results' in locals() else 0
                }
            }
        
        # 4. ë¶„ì„ í•¨ìˆ˜ ë…¸ë“œ (ìˆœìˆ˜ í•¨ìˆ˜)
        def analysis_function_node(state: MultiAgentState):
            """ë¶„ì„ í•¨ìˆ˜ ë…¸ë“œ - ë°ì´í„° ì²˜ë¦¬ ë° í†µê³„"""
            print("**** ë¶„ì„ í•¨ìˆ˜ ë…¸ë“œ ì‘ì—… ì‹œì‘")
            
            research_data = state['research_data']
            
            # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ë¶„ì„
            analysis_metrics = {
                "data_length": len(research_data),
                "sentence_count": research_data.count('.') + research_data.count('!') + research_data.count('?'),
                "keyword_frequency": {},
                "sentiment_score": 0.7  # ê°€ì§œ ê°ì • ì ìˆ˜ë¡œ ì‹¤ì œ í”„ë¡œì íŠ¸ ì‹œ ê°ì • ë¶„ë¥˜ ëª¨ë¸ ë“±ì„ í™œìš©í•´ì„œ ì‚¬ìš©í•´ì•¼í•¨
            }
            
            # í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„ (ê°„ë‹¨ ë²„ì „)
            words = re.findall(r'\w+', research_data.lower())
            common_words = ['ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì˜', 'ì™€', 'ê³¼']
            filtered_words = [word for word in words if word not in common_words and len(word) > 1]
            
            # ìƒìœ„ 3ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ
            word_freq = {}
            for word in filtered_words:
                word_freq[word] = word_freq.get(word, 0) + 1
            
            top_keywords = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:3]
            analysis_metrics["keyword_frequency"] = dict(top_keywords)
            
            # ë¶„ì„ ê²°ê³¼ ìš”ì•½
            analysis_result = f"""
                                **** ë°ì´í„° ë¶„ì„ ê²°ê³¼:
                                - ë°ì´í„° ê¸¸ì´: {analysis_metrics['data_length']} ë¬¸ì
                                - ë¬¸ì¥ ìˆ˜: {analysis_metrics['sentence_count']}ê°œ
                                - ì£¼ìš” í‚¤ì›Œë“œ: {', '.join([k for k, v in top_keywords])}
                                - ê°ì • ì ìˆ˜: {analysis_metrics['sentiment_score']} (ê¸ì •ì )
                                - ë¶„ì„ ì™„ë£Œ ì‹œê°„: í˜„ì¬
                                """
            
            return {
                "user_request": state['user_request'],
                "research_data": state['research_data'],
                "analysis_result": analysis_result,
                "draft_content": state.get('draft_content', ''),
                "final_output": state.get('final_output', ''),
                "current_step": "analysis_complete",
                "metadata": {**state.get('metadata', {}), "analysis_metrics": analysis_metrics}
            }
        
        # 5. ì‘ê°€ Agent (LLM + í…ìŠ¤íŠ¸ ìƒì„±)
        def writer_agent(state: MultiAgentState):
            """ì‘ê°€ Agent - ì½˜í…ì¸  ì‘ì„± ì „ë¬¸"""
            print("==== ì‘ê°€ Agent ì‘ì—… ì‹œì‘")
            
            user_request = state['user_request']
            research_data = state['research_data']
            analysis_result = state['analysis_result']
            
            # ì‘ê°€ê°€ ì¢…í•©ì ì¸ ì½˜í…ì¸  ì‘ì„±
            writing_prompt = f"""
                                ì‚¬ìš©ì ìš”ì²­: {user_request}

                                ì—°êµ¬ ë°ì´í„°:
                                {research_data}

                                ë¶„ì„ ê²°ê³¼:
                                {analysis_result}

                                ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ìš”ì²­ì— ëŒ€í•œ ì™„ì„±ë„ ë†’ì€ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
                                êµ¬ì¡°í™”ë˜ê³  ì½ê¸° ì‰¬ìš°ë©°, í•µì‹¬ ì •ë³´ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
                                ë…¼ë¬¸ í˜•íƒœë¡œ ì‘ì„±í•´ì•¼í•˜ë©° í•œê¸€ë¡œë§Œ ì‘ì„±í•©ë‹ˆë‹¤.
                                """
            
            draft_content = llm.invoke(writing_prompt)
            
            return {
                "user_request": state['user_request'],
                "research_data": state['research_data'],
                "analysis_result": state['analysis_result'],
                "draft_content": draft_content,
                "final_output": state.get('final_output', ''),
                "current_step": "writing_complete",
                "metadata": state.get('metadata', {})
            }
        
        # 6. ìµœì¢… ì •ë¦¬ ë…¸ë“œ (í•¨ìˆ˜)
        def finalize_output_node(state: MultiAgentState):
            """ìµœì¢… ì •ë¦¬ ë…¸ë“œ - ê²°ê³¼ í¬ë§·íŒ…"""
            print("==== ìµœì¢… ì •ë¦¬ ë…¸ë“œ ì‘ì—… ì‹œì‘")
            
            draft_content = state['draft_content']
            metadata = state.get('metadata', {})
            
            # ìµœì¢… ì¶œë ¥ í¬ë§·íŒ…
            final_output = f"""
                            -- í•˜ì´ë¸Œë¦¬ë“œ ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—… ê²°ê³¼ --

                            {draft_content}

                            =========================================
                            **** ì‘ì—… ì •ë³´:
                            â€¢ ê²€ìƒ‰ ìˆ˜í–‰: {'ì˜ˆ' if metadata.get('search_performed') else 'ì•„ë‹ˆì˜¤'}
                            â€¢ ê²€ìƒ‰ í‚¤ì›Œë“œ: {metadata.get('search_keywords', 'N/A')}
                            â€¢ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {metadata.get('search_results_count', 0)}ê°œ
                            â€¢ ë¶„ì„ ì™„ë£Œ: ì˜ˆ
                            â€¢ ì‘ê°€ ì‘ì—…: ì™„ë£Œ

                            **** ì‹œìŠ¤í…œ ì •ë³´:
                            â€¢ ì—°êµ¬ì Agent: LLM + duckduckgo-search
                            â€¢ ë¶„ì„ ë…¸ë“œ: ìˆœìˆ˜ í•¨ìˆ˜ (í…ìŠ¤íŠ¸ ë¶„ì„)
                            â€¢ ì‘ê°€ Agent: LLM + í…ìŠ¤íŠ¸ ìƒì„±  
                            â€¢ ìµœì¢… ì •ë¦¬: í•¨ìˆ˜ ë…¸ë“œ

                            **** ì‚¬ìš©ëœ ë„êµ¬:
                            â€¢ DuckDuckGo Search API (ì‹¤ì‹œê°„ ê²€ìƒ‰)
                            â€¢ í…ìŠ¤íŠ¸ ë¶„ì„ í•¨ìˆ˜
                            â€¢ LLM ì–¸ì–´ ëª¨ë¸ (Ollama)
                            """
            
            return {
                "user_request": state['user_request'],
                "research_data": state['research_data'], 
                "analysis_result": state['analysis_result'],
                "draft_content": state['draft_content'],
                "final_output": final_output,
                "current_step": "completed",
                "metadata": metadata
            }
        
        # 7. Graph êµ¬ì„±
        workflow = StateGraph(MultiAgentState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("researcher", researcher_agent)          # LLM Agent
        workflow.add_node("analyzer", analysis_function_node)      # í•¨ìˆ˜ ë…¸ë“œ
        workflow.add_node("writer", writer_agent)                  # LLM Agent  
        workflow.add_node("finalizer", finalize_output_node)       # í•¨ìˆ˜ ë…¸ë“œ
        
        # ìˆœì°¨ì  íë¦„ ì„¤ì • => ì¡°ê±´ì  ë¶„ê¸°ê°€ í•„ìš” ì—†ëŠ” ìƒí™©
        workflow.set_entry_point("researcher")
        workflow.add_edge("researcher", "analyzer")
        workflow.add_edge("analyzer", "writer")
        workflow.add_edge("writer", "finalizer")
        workflow.add_edge("finalizer", END)
        
        # ì»´íŒŒì¼
        app = workflow.compile()
        print("âœ… í•˜ì´ë¸Œë¦¬ë“œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ")
        
        return app
        
    except Exception as e:
        print(f"==== í•˜ì´ë¸Œë¦¬ë“œ ë©€í‹° ì—ì´ì „íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def test_hybrid_multi_agent():
    """í•˜ì´ë¸Œë¦¬ë“œ ë©€í‹° ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸"""
    print("\==== í•˜ì´ë¸Œë¦¬ë“œ ë©€í‹° ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸")
    print("="*50)
    
    agent_system = create_hybrid_multi_agent()
    if not agent_system:
        return
    
    test_cases = [
        # "ChatGPT ìµœì‹  ê¸°ëŠ¥ì— ëŒ€í•´ ë¶„ì„í•´ì¤˜",
        "2026ë…„ AI ê¸°ìˆ  ë™í–¥ì„ ì•Œë ¤ì£¼ì„¸ìš”",
        # "duckduckgo-search ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ë²•ì€?",
        # "Pythonê³¼ JavaScript ë¹„êµ ë¶„ì„"
    ]
    
    for i, test_request in enumerate(test_cases, 1):
        print(f"\n{'='*60}")
        print(f"==== í…ŒìŠ¤íŠ¸ {i}: {test_request}")
        print("="*60)
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state = {
            "user_request": test_request,
            "research_data": "",
            "analysis_result": "",
            "draft_content": "",
            "final_output": "",
            "current_step": "start",
            "metadata": {}
        }
        
        try:
            # ë©€í‹° ì—ì´ì „íŠ¸ ì‹¤í–‰
            print("==== ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—… ì‹œì‘...")
            result = agent_system.invoke(initial_state)
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"\==== ìµœì¢… ê²°ê³¼:")
            print(result['final_output'])
            
        except Exception as e:
            print(f"==== í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        # print(f"\==== ë‹¤ìŒ í…ŒìŠ¤íŠ¸ê¹Œì§€ ì ì‹œ ëŒ€ê¸°...")
        import time
        time.sleep(2)

def explain_hybrid_architecture():
    """í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ ì„¤ëª…"""
    print("\nğŸ—ï¸ í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ êµ¬ì¡°")
    print("="*40)
    
    architecture = {
        "ì—°êµ¬ì Agent (LLM)": {
            "ì—­í• ": "ì‹¤ì‹œê°„ ì •ë³´ ê²€ìƒ‰ ë° í•„ìš”ì„± íŒë‹¨",
            "ë„êµ¬": "duckduckgo-search ë¼ì´ë¸ŒëŸ¬ë¦¬",
            "íŠ¹ì§•": "ì‹¤ì œ ì›¹ ê²€ìƒ‰, ìµœì‹  ì •ë³´ ìˆ˜ì§‘",
            "ë¹„ìš©": "ğŸ’°ğŸ’°ğŸ’°"
        },
        "ë¶„ì„ ë…¸ë“œ (í•¨ìˆ˜)": {
            "ì—­í• ": "ë°ì´í„° ë¶„ì„ ë° í†µê³„ ì²˜ë¦¬",
            "ë„êµ¬": "í…ìŠ¤íŠ¸ ë¶„ì„, í‚¤ì›Œë“œ ì¶”ì¶œ",
            "íŠ¹ì§•": "ë¹ ë¥¸ ì²˜ë¦¬, ì˜ˆì¸¡ ê°€ëŠ¥í•œ ê²°ê³¼",
            "ë¹„ìš©": "ğŸ’°"
        },
        "ì‘ê°€ Agent (LLM)": {
            "ì—­í• ": "ì¢…í•©ì ì¸ ì½˜í…ì¸  ì‘ì„±",
            "ë„êµ¬": "í…ìŠ¤íŠ¸ ìƒì„±, êµ¬ì¡°í™”",
            "íŠ¹ì§•": "ì°½ì˜ì  ì‘ì„±, ì‚¬ìš©ì ë§ì¶¤",
            "ë¹„ìš©": "ğŸ’°ğŸ’°ğŸ’°"
        },
        "ì •ë¦¬ ë…¸ë“œ (í•¨ìˆ˜)": {
            "ì—­í• ": "ìµœì¢… ì¶œë ¥ í¬ë§·íŒ…",
            "ë„êµ¬": "í…œí”Œë¦¿ ì²˜ë¦¬, ë©”íƒ€ë°ì´í„° ì¶”ê°€",
            "íŠ¹ì§•": "ì¼ê´€ëœ í˜•ì‹, ë¹ ë¥¸ ì²˜ë¦¬",
            "ë¹„ìš©": "ğŸ’°"
        }
    }
    
    for component, details in architecture.items():
        print(f"\nğŸ”§ {component}")
        for key, value in details.items():
            print(f"   {key}: {value}")
    
    print(f"\nğŸ’¡ í•˜ì´ë¸Œë¦¬ë“œì˜ ì¥ì :")
    print("  â€¢ ì´ LLM í˜¸ì¶œ: 2íšŒ (ì—°êµ¬ì + ì‘ê°€)")
    print("  â€¢ ë¹ ë¥¸ ì²˜ë¦¬: í•¨ìˆ˜ ë…¸ë“œë¡œ ë¶„ì„/ì •ë¦¬")
    print("  â€¢ ì°½ì˜ì„±: í•„ìš”í•œ ê³³ì—ë§Œ LLM ì‚¬ìš©")
    print("  â€¢ ë¹„ìš© íš¨ìœ¨: ìˆœìˆ˜ í•¨ìˆ˜ë¡œ ë¹„ìš© ì ˆì•½")

def show_workflow_diagram():
    """ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨"""
    print(f"\nğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°")
    print("="*45)
    
    workflow_diagram = """
    ì‚¬ìš©ì ìš”ì²­
         â†“
    ğŸ¤– ì—°êµ¬ì Agent (LLM)
    â”œâ”€ ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨
    â”œâ”€ ê²€ìƒ‰ ì‹¤í–‰
    â””â”€ ë°ì´í„° ìˆ˜ì§‘
         â†“
    âš™ï¸ ë¶„ì„ ë…¸ë“œ (í•¨ìˆ˜)
    â”œâ”€ í…ìŠ¤íŠ¸ ë¶„ì„
    â”œâ”€ í‚¤ì›Œë“œ ì¶”ì¶œ
    â””â”€ í†µê³„ ê³„ì‚°
         â†“
    âœï¸ ì‘ê°€ Agent (LLM)
    â”œâ”€ ì¢…í•© ë¶„ì„
    â”œâ”€ ì½˜í…ì¸  ì‘ì„±
    â””â”€ êµ¬ì¡°í™”
         â†“
    ğŸ“‹ ì •ë¦¬ ë…¸ë“œ (í•¨ìˆ˜)
    â”œâ”€ í¬ë§·íŒ…
    â”œâ”€ ë©”íƒ€ë°ì´í„° ì¶”ê°€
    â””â”€ ìµœì¢… ì¶œë ¥
         â†“
    âœ… ì™„ë£Œëœ ê²°ê³¼
    """
    
    print(workflow_diagram)
    
    print("\nâ±ï¸ ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„:")
    print("  â€¢ ì—°êµ¬ì Agent: 30-60ì´ˆ")
    print("  â€¢ ë¶„ì„ ë…¸ë“œ: 1-2ì´ˆ")
    print("  â€¢ ì‘ê°€ Agent: 30-60ì´ˆ")
    print("  â€¢ ì •ë¦¬ ë…¸ë“œ: 1ì´ˆ")
    print("  â€¢ ì´í•©: ì•½ 1-2ë¶„")

if __name__ == "__main__":
    # ì•„í‚¤í…ì²˜ ì„¤ëª…
    explain_hybrid_architecture()
    
    # ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨
    show_workflow_diagram()
    
    # ì‹¤ì œ ì‹œìŠ¤í…œ ìƒì„± ë° í…ŒìŠ¤íŠ¸
    print(f"\n{'='*80}")
    print("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    test_hybrid_multi_agent()